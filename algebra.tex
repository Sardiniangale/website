%% LyX 2.4.3 created this file.  For more info, see https://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[american]{article}
\renewcommand{\familydefault}{\sfdefault}
\usepackage[T1]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{babel}
\begin{document}
\title{Linear Algebra \& Geometry}
\date{April 10, 2025}
\author{Giacomo}

\maketitle
\includegraphics[scale=0.5]{/home/guc/Pictures/Cover}

\newpage{}

\part*{Pre-Det}

\section*{Spaces (Spazi Vettoriali)}

\textquotedbl I have not failed. I've just found 10,000 ways that
won't work.\textquotedbl{}

\subsection*{Basic Definitions}

\paragraph{Vectors (Vettori):}

Vectors are mathematical tools which can be visualized as arrows.
They hold tow primary operations, scaling and addition. 

\subparagraph{Scaling:}

Scaling involves multiplying a scalar quantity $\lambda$ which doesn't
have a direction with the vectors. This either amplifies or reduces
the vector without changing the ``line its on''

\[
\lambda\in\mathbb{R},v=\left(\begin{array}{c}
v_{1}\\
v_{2}
\end{array}\right)\in R^{2}:\lambda\cdot v=\left(\begin{array}{c}
\lambda v_{1}\\
\lambda v_{2}
\end{array}\right)
\]


\subparagraph*{Addition:}

Addition involves adding two vectors to make a new vector

\[
v=\left(\begin{array}{c}
v_{1}\\
v_{2}
\end{array}\right),w=\left(\begin{array}{c}
w_{1}\\
w_{2}
\end{array}\right)\in R^{2}:v+w=\left(\begin{array}{c}
v_{1}+w_{1}\\
v_{2}+w_{2}
\end{array}\right)
\]


\paragraph*{Subsets (Sottoinsiemi):}

This is a set where all the elements are contained within another
set. For linear algebra it could be a collection of vectors within
a vector space e.g $\mathbb{R}^{3}$

\[
S=\left\{ \left(x,y,0\right)|x,y\in\mathbb{R}\right\} 
\]


\paragraph*{Proper Subsets (Sottoinsiemi Propri):}

This is a subset that is always smaller than the original set. The
exact definition is: 

\begin{equation}
A\subsetneq B
\end{equation}
if:

1. Containment: ``Every element of A is also a element of B''

\begin{equation}
\forall x(x\in A\Longmapsto x\in B)
\end{equation}

2. Not equal: ``There exists at least one element in B that is not
A''

\begin{equation}
\exists y(y\in B\land y\notin A)
\end{equation}


\paragraph*{Supersets (Soprainsiemi):}

This is the opposite of a subset. If $A\subset B$, then B is a superset
of A

\subsection*{Linear Independence}

Let V be a vector space over a field F. $S\subseteq V$ is linearly
independent if the following conditions are true:

For a collection of vectors $\left\{ v_{1},v_{2},...,v_{n}\right\} \subseteq S$
and scalars $\left\{ a_{1},a_{2},...,a_{n}\right\} \in F$

\begin{equation}
a_{1}v_{1}+a_{2}v_{2}+...+a_{n}v_{n}=0
\end{equation}

i.e every single variant of a up to n has to equal zero. If it does
not, it is linearly dependent

\subsection*{Dimensions of a space}

The dimension (dimensione) of a vector space (spazio vettoriale) is
the number of vectors in any basis (base) for that space. A basis
(base) is a set of vectors that are linearly independent (linearmente
indipendenti) and span (generano) the entire space.

\subsection*{Sum of subspace (Somma di sottospazi)}

Let U and V be subspaces (sottospazi) of a vector space (spazio vettoriale)
V over a field $\mathbb{F}$. The sum (somma) can be defined as:

\begin{equation}
U+V=\left\{ u+v|u\in U,v\in V\right\} 
\end{equation}


\subsection*{Direct Sum (Somma diretta)}

U+V is called a direct sum, if the intersection of U and V is trivial
???- (Further desc required) then:

\[
U\cap V=\left\{ 0\right\} 
\]
 The direct sum can be denoted as $U\oplus V:$--to be expanded upon

\[
z=u+v
\]


\section*{Inner Products}

\subsection*{Definition:}

\subparagraph{For $\mathbb{R}$}

For a vectors $v=(v_{1}....v_{n})$ and $w=(w_{1}....w_{n})$ it is

\begin{equation}
<v,w>=v\cdot w=\sum_{i=1}^{n}v_{i}w_{i}
\end{equation}


\subparagraph*{For $\mathbb{C}$}

For a complex vectors $v=(v_{1}....v_{n})$ and $w=(w_{1}....w_{n})$
it is

\begin{equation}
<v,w>=\sum_{i=1}^{n}v_{i}\overline{w}_{i}
\end{equation}


\subsection*{Specifics in $\mathbb{R}$}

\subsubsection*{Proof:}

Lets take a vector u and a vector v and say that they are orthogonal.
Because of the orthogonality there is some $\lambda$ which allows
the transformation. 

\[
\left(\begin{array}{c}
v_{1}\\
v_{2}
\end{array}\right)=\lambda\left(\begin{array}{c}
-u_{2}\\
u_{1}
\end{array}\right)
\]

(Below the $\leftrightarroweq$ is being used as a substitute for
and). 

\[
u_{1}\cdot v_{1}=-\cancelto{v_{2}}{u_{1}\lambda}u_{2}\leftrightarroweq u_{2}\cdot v_{2}=\cancelto{-v_{1}}{u_{2}\lambda}u_{1}
\]

Since v2 and -v1 equal to those terms above they cancel out the unknown
$\lambda$

\[
u_{1}\cdot v_{1}=-v_{2}\cdot u_{2}\leftrightarroweq u_{2}\cdot v_{2}=-v_{1}u_{1}
\]

Since both sides are now the same formula, we can move them from one
side to the other removing the negative equaling =0

\[
u_{1}v_{1}+u_{2}v_{2}=0
\]

\[
u_{1}v_{1}\Rightarrow<u,v>
\]


\subsubsection*{Length:}

\subsubsection*{Angle Between Vectors:}

\subsubsection*{Projection:}

\subsubsection*{Orthogonality:}

\section*{Matrixes}

\part*{Post-Det}
\end{document}
